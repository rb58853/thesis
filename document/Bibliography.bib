@article{transformers,
 author = {Ashish Vaswani. Noam Shazeer. Niki Parmar. Jakob Uszkoreit. Llion Jones. Aidan N. Gomez. Lukasz Kaiser. Illia Polosukhin. },
 title = {Attention Is All You Need},
 journal = {31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA,},
 year = {2017}
}

@article{blip,
 author = {Junnan Li, Dongxu Li, Caiming Xiong y Steven Hoi.},
 title = {BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation},
 journal = { Salesforce Research, deepai.org},
 year = {2022}
}

@article{clip-paper,
 author = {Alec Radford. Jong Wook Kim. Chris Hallacy. Aditya Ramesh. Gabriel Goh. Sandhini Agarwal. Girish Sastry. Amanda Askell. Pamela Mishkin. Jack Clark. Gretchen Krueger. Ilya Sutskever.},
 title = {Learning Transferable Visual Models From Natural Language Supervision},
 journal = {OpenIA},
 year = {2021}
}

@article{clip,
 title={CLIP: Connecting text and images},
 author={OpenAI},
 year={2021},
 url={https://openai.com/research/clip},
}


@article{gpt-4v,
    author = {Zhengyuan Yang. Linjie Li. Kevin Lin. Jianfeng Wang. Chung-Ching Lin. Zicheng Liu. Lijuan Wang.},
    title = {The Dawn of LMMs:Preliminary Explorations with GPT-4V(ision)},
    journal = {Microsoft Corporation},
    year = {2023},
    month = octubre
}

@article{llava,
    author = {Haotian Liu. Chunyuan Li. Qingyang Wu. Yong Jae Lee.},
    title = {Visual Instruction Tuning},
    journal = {Microsoft Research},
    year = {2023},
    month = abril
}

@article{Li2021MultilevelSL,
 title={Multi-level similarity learning for image-text retrieval},
 author={Wenhui Li and Song Yang and Yan Wang and Dan Song and Xuan Li},
 journal={Inf. Process. Manag.},
 year={2021},
 volume={58},
 pages={102432},
 url={https://api.semanticscholar.org/CorpusID:229390149}
}

@inproceedings{Baldrati2022,
 author = {Baldrati, Francesco and others},
 title = {Effective Conditioned and Composed Image Retrieval: Combining CLIP-Based Features},
 booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
 year = {2022},
 month = {June},
 url = {https://openaccess.thecvf.com/content/CVPR2022/papers/Baldrati_Effective_Conditioned_and_Composed_Image_Retrieval_Combining_CLIP-Based_Features_CVPR_2022_paper.pdf}
}

@misc{keita2023clip,
   author = {Keita, Zoumana},
   title = {Text-to-Image and Image-to-Image Search Using CLIP},
   year = {2023},
   url = {https://www.pinecone.io/learn/clip-image-search/},
}

@article{mdpi2023clip,
 title={CLIP Model and The Importance of Multimodal Embeddings},
 author={Cao, Min and Li, Shiping and Li, Juntao and Nie, Liqiang and Zhang, Min},
 journal={MDPI},
 volume={14},
 number={7},
 pages={392},
 year={2023},
 publisher={Multidisciplinary Digital Publishing Institute}
}

@misc{tensorflow,
 author = {Google Inc.},
 title = {Attention - TensorFlow API Documentation},
 url = {https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention},
}
@article{sam-paper,
 title={Segment Anything},
 author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Doll{\'a}r, Piotr and Girshick, Ross},
 journal={arXiv:2304.02643},
 year={2023}
}

@misc{gpt2,
   author = {Radford, Alec and Narasimhan, Karthik and Salimans, Timur and Sutskever, Ilya},
   title = {Language Models are Unsupervised Multitask Learners},
   year = {2017},
   url = {https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf}
}

@misc{bert,
   author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
   title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
   year = {2018},
   url = {https://arxiv.org/abs/1810.04805}
}

@misc{t5,
  author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Skantze, Matteo and Hennigan, Patrick},
  title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  year = {2019},
  url = {https://arxiv.org/abs/1910.10683}
}

@misc{sly,
 author = {David Beazley},
 title = {Sly Lex Yacc},
 year = {2016},
 url = {https://sly.readthedocs.io/en/latest/sly.html}
}

@misc{huggingface2022blip,
 title={Huggingface BLIP},
 author={Huggingface},
 year={2022},
 publisher={GitHub},
 howpublished={\url{https://huggingface.co/models?filter=blip}}
}
@misc{li2022blip_github,
 title={BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation},
 author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven C. H.},
 year={2022},
 publisher={GitHub},
 howpublished={\url{https://github.com/salesforce/BLIP}}
}
@misc{rose2022blip,
 title={BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation},
 author={Rose, Donald},
 year={2022},
 publisher={Salesforce AI Research Blog},
 howpublished={\url{https://blog.salesforceairesearch.com/blip-bootstrapping-language-image-pretraining/}}
}

@misc{git-clip,
 title={CLIP: OpenAI's Official GitHub Repository},
 author={OpenAI},
 year={2021},
 publisher={GitHub},
 howpublished={\url{https://github.com/openai/CLIP}}
}

@misc{huggingface2022clip,
 title={Huggingface CLIP},
 author={Huggingface},
 year={2022},
 publisher={GitHub},
 howpublished={\url{https://huggingface.co/models?filter=clip}}
}

@misc{huggingface2022sam,
 title={SAM Documentation},
 author={Hugging Face},
 year={2022},
 publisher={Hugging Face},
 howpublished={\url{https://huggingface.co/docs/transformers/model_doc/sam}}
}

@misc{gpt3,
 title={GPT-3: Language Models are Unsupervised Multitask Learners},
 author={Radford, Alec and Narasimhan, Karthik and Salimans, Timur and Sifre, Llion and Amodei, Dario},
 year={2020},
 publisher={OpenAI},
 howpublished={\url{https://arxiv.org/abs/2005.14165}}
}
@article{clip2-paper,
 title={CLIP$^2$: Contrastive Language-Image-Point Pretraining from Real-World Point Cloud Data},
 author={Zeng, Yihan and Jiang, Chenhan and Mao, Jiageng and Han, Jianhua and Ye, Chaoqiang and Huang, Qingqiu and Yeung, Dit-Yan and Yang, Zhen and Liang, Xiaodan and Xu, Hang},
 year={2023},
 journal={arXiv preprint arXiv:2303.12417},
 howpublished={\url{https://arxiv.org/abs/2303.12417}}
}

@article{sentence-level,
 title={Sentence-level Prompts Benefit Composed Image Retrieval},
 author={Bai, Yang and Xu, Xinxing and Liu, Yong and Khan, Salman and Khan, Fahad and Zuo, Wangmeng and Goh, Rick Siow Mong and Feng, Chun-Mei},
 journal={arXiv preprint arXiv:2310.05473},
 year={2023}
}

@article{blip-2,
 title={BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models},
 author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
 journal={arXiv preprint arXiv:2301.12597},
 year={2023}
}

@misc{gpt4,
   author = {OpenAI},
   title = {GPT-4: An AI Multimodal That Claims to Be of Latest Generation},
   year = {2023},
   publisher = {TechCrunch},
   url = {https://techcrunch.com/2023/03/14/openai-launches-gpt-4-a-multimodal-ai-that-claims-to-be-of-latest-generation/},
}
@misc{huggingface-blip2,
   author = {Hugging Face},
   title = {BLIP-2},
   year = {2022},
   url = {https://huggingface.co/docs/transformers/main/model_doc/blip-2}
}

@phdthesis{CBIR-DeepLearning,
  author = {Vikram Singh, Anshuman},
  title = {Content-Based Image Retrieval using Deep Learning},
  year = {2015},
  school = {Rochester Institute of Technology},
  url = {https://scholarworks.rit.edu/theses/8828}
}

@article{sumbul2020,
  author = {Sumbul, Gencer and Kang, Jian and Demir, Begüm},
  title = {Deep Learning for Image Search and Retrieval in Large Remote Sensing Archives},
  year = {2020},
  journal = {arXiv preprint arXiv:2004.01613},
  url = {https://arxiv.org/abs/2004.01613}
}

@article{dubey2020,
 author = {Dubey, Shiv Ram},
 title = {A Decade Survey of Content Based Image Retrieval using Deep Learning},
 year = {2021},
 journal = {arXiv preprint arXiv:2012.00641},
 url = {https://arxiv.org/abs/2012.00641}
}

@article{embedding1,
 author = {Barz, Björn and Denzler, Joachim},
 title = {Hierarchy-based Image Embeddings for Semantic Image Retrieval},
 year = {2018},
 journal = {arXiv preprint arXiv:1809.09924},
 url = {https://arxiv.org/abs/1809.09924}
}

@online{embedding2,
 author = {The Tenyks Blogger},
 title = {Multi-modal Image Search with Embeddings & Vector DBs},
 year = {2023},
 url = {https://medium.com/@tenyks_blogger/multi-modal-image-search-with-embeddings-vector-dbs-cee61c70a88a}
}

@online{BuildingImageClip-20ms,
 author = {Antti Havanko},
 title = {Building Image search with OpenAI Clip},
 year = {2022},
 url = {https://anttihavanko.medium.com/building-image-search-with-openai-clip-5a1deaa7a6e2}
}
