\begin{resumen}
	El tema de la recuperación precisa de imágenes representa un desafío constante en el campo de la ciencia de la computación. En esta tesis, se propone un enfoque innovador para abordar dicho problema, aplicando los modelos de Segmentación \textit{Segment Anything} (SAM) y el modelo \textit{Contrastive Language–Image Pretraining} (CLIP) para la generación de embeddings. En este estudio, se explora la recuperación de imágenes mediante consultas precisas, empleando el modelo \textit{Contrastive Language-Image Pretraining} y la generación de embeddings multimodales con el mismo. Se pone especial énfasis en la recuperación de imágenes basada en la posición, procesando tanto texto como imágenes para extraer características con este fin.
	 
	\end{resumen}
	
	\begin{abstract}
	The topic of precise image recovery presents a constant challenge in the field of computer science. In this thesis, an innovative approach is proposed to tackle this issue, utilizing the Segmentation models \textit{Segment Anything} (SAM) and the \textit{Contrastive Language–Image Pretraining} (CLIP) model for generating embeddings. In this study, the recovery of images through accurate queries is explored, using the \textit{Contrastive Language-Image Pretraining} model and multimodal embedding generation. A special emphasis is placed on position-based image recovery, processing both text and images to extract features for this purpose.
	\end{abstract}