\begin{resumen}
	En esta tesis se aborda el problema de la recuperación precisa de imágenes. Para ello se utiliza un nuevo enfoque: la aplicación de los modelos de Segmentación Segment Anything (SAM) y el  modelo Constractive Language-Image Pretraining (CLIP) para la generación de embeddings multimodales. En el trabajo se pone especial énfasis en la recuperación de  imágenes mediante consultas precisas, para ello se tiene en cuenta la posición de segmentos de imágenes que componenen la misma, procesando tanto textos como imágenes.
	\end{resumen}
	
	\begin{abstract}
		This thesis addresses the problem of precise image retrieval. For this purpose, a new approach is applied: the application of the Segment Anything (SAM) segmentation models and the Constructive Language-Image Pretraining (CLIP) model for the generation of multimodal embeddings. In this work, special emphasis is placed on image recovery through accurate queries, taking into account the position of image segments that make up the same, processing both texts and images.
	\end{abstract}