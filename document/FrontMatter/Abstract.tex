\begin{resumen}
	En esta tesis se aborda el problema de la recuperación precisa de imágenes. En el trabajo se utiliza un nuevo enfoque: la aplicación de los modelos de Segmentación Segment Anything (SAM) y el  modelo Constractive Language-Image Pretraining (CLIP) para la generación de embeddings multimodales. En el trabajo se pone especial énfasis en la recuperación de  imágenes mediante consultas precisas, para ello se tiene en cuenta la posición de segmentos de imágenes que componenen la misma, procesando tanto textos como imágenes.
	\end{resumen}
	
	\begin{abstract}
		In this thesis, the problem of precise image retrieval is addressed. The work employs a new approach: the application of the Segment Anything (SAM) segmentation models and the Constractive Language-Image Pretraining (CLIP) model for the generation of multimodal embeddings. Special emphasis is placed on image retrieval via precise queries, taking into account the position of image segments that compose the same, processing both text and images.
	\end{abstract}